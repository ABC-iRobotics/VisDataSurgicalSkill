{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving ROI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VISUALISE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '../data/JIGSAWS/'\n",
    "\n",
    "skills = ['Knot_Tying', 'Needle_Passing', 'Suturing']\n",
    "\n",
    "cornerNum = 30 #used not just for determining the number of points to select for each feature (each tool)\n",
    "               #but also for making sure every ROI has all the possible feature points\n",
    "\n",
    "feature_params = dict( maxCorners = cornerNum,\n",
    "                       qualityLevel = 0.6,\n",
    "                       minDistance = 3,\n",
    "                       blockSize = 3,\n",
    "                       gradientSize = 5)\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import pyautogui\n",
    "\n",
    "def getJIGSAWvideoTitles():\n",
    "    dir_name = root + skills[0] + '/video/'\n",
    "    knot_list = [os.path.basename(x) for x in glob.glob(dir_name+'*.avi')]\n",
    "    dir_name = root + skills[1] + '/video/'\n",
    "    needle_list = [os.path.basename(x) for x in glob.glob(dir_name+'*.avi')]\n",
    "    dir_name = root + skills[2] + '/video/'\n",
    "    suture_list = [os.path.basename(x) for x in glob.glob(dir_name+'*.avi')]\n",
    "    knot_list.sort()\n",
    "    needle_list.sort()\n",
    "    suture_list.sort()\n",
    "    return knot_list, needle_list, suture_list\n",
    "\n",
    "knot_list, needle_list, suture_list = getJIGSAWvideoTitles()\n",
    "\n",
    "def parseFileName(filename):\n",
    "    var = filename\n",
    "    index = 0\n",
    "    skill = var[index] #gathering skill-string\n",
    "    index += 1\n",
    "    while(var[index] != '_'):\n",
    "        skill += var[index]\n",
    "        index += 1 #finding first underscore\n",
    "    if filename[0] != 'S': #in case of Suturing there is one less underscore\n",
    "        skill += var[index]\n",
    "        index += 1\n",
    "        while(var[index] != '_'):\n",
    "            skill += var[index]\n",
    "            index += 1\n",
    "    index += 1 #skipping second underscore\n",
    "    user = var[index] #saving user_id\n",
    "    index += 1 #skipping userID\n",
    "    attempt = var[index] #first digit of attempt id\n",
    "    index += 1\n",
    "    while(var[index].isdigit()):\n",
    "        attempt += var[index]\n",
    "        index += 1\n",
    "    while(var[index] != '.'):\n",
    "        index += 1\n",
    "    capture = var[index-1] #capture_num is right before the dot\n",
    "    return  user, attempt, capture, skill\n",
    "\n",
    "def getGestureSeparatedFrameRanges(filename):\n",
    "    gestures = []\n",
    "    frame_begin = []\n",
    "    frame_end = []\n",
    "    with open(filename) as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            i = 0\n",
    "            temp = \"\"\n",
    "            while line[i] != ' ':\n",
    "                temp += line[i]\n",
    "                i += 1\n",
    "            frame_begin.append(int(temp)) #first characters form the beginning frames\n",
    "            temp = \"\"\n",
    "            while line[i] == ' ':\n",
    "                i += 1 #skip spaces\n",
    "            while line[i] != ' ':\n",
    "                temp += line[i]\n",
    "                i += 1\n",
    "            frame_end.append(int(temp)) #second is the end frame\n",
    "            temp = \"\"\n",
    "            while line[i] == ' ':\n",
    "                i += 1 #skip spaces\n",
    "            while line[i] != ' ' and line[i] != '\\n':\n",
    "                temp += line[i]\n",
    "                i += 1\n",
    "            gestures.append(temp)\n",
    "    output = np.vstack((np.array(gestures), np.array(frame_begin), np.array(frame_end)))\n",
    "    f.close()\n",
    "    return output\n",
    "\n",
    "def TranscriptionPath(user, attempt, skill):\n",
    "    path = root + skill + '/transcriptions/'+ skill + '_' + user +  attempt + '.txt'\n",
    "    return path\n",
    "\n",
    "def ROIdataPath(user, attempt, skill, capture):\n",
    "    path = root + skill + '/ROI_data/'+ skill + '_' + user +  attempt +  '_' + capture\n",
    "    return path\n",
    "\n",
    "def ChooseROIs(frame, frame_begin, cap):\n",
    "    num_of_ROIs = 2\n",
    "    actual_frame_begin = int(frame_begin)\n",
    "    # Specify a vector of rectangles (ROI) \n",
    "    fromCenter = True\n",
    "    im = cv.medianBlur(frame,5)\n",
    "    im = cv.adaptiveThreshold(im,255,cv.ADAPTIVE_THRESH_GAUSSIAN_C,cv.THRESH_BINARY,11,2)\n",
    "    # Select multiple rectangles\n",
    "    i = 0\n",
    "    while i < num_of_ROIs:\n",
    "        title = \"Image\"\n",
    "        r = cv.selectROI(title, frame, fromCenter)\n",
    "        if r == (0,0,0,0):\n",
    "            i = 0\n",
    "            ret, frame = cap.read()\n",
    "            frame = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "            actual_frame_begin += 1\n",
    "        else:\n",
    "            if VISUALISE:\n",
    "                cv.imshow('Original',frame)\n",
    "            im = cv.medianBlur(frame,5)\n",
    "            if VISUALISE:\n",
    "                cv.imshow('Blurred', im)\n",
    "            im = cv.adaptiveThreshold(im,255,cv.ADAPTIVE_THRESH_GAUSSIAN_C,cv.THRESH_BINARY,11,2)\n",
    "            if VISUALISE:\n",
    "                cv.imshow('Thresholded', im)\n",
    "            imCrop = im[int(r[1]):int(r[1]+r[3]), int(r[0]):int(r[0]+r[2])]\n",
    "            img = np.zeros(frame.shape).astype(np.float32)\n",
    "            img[int(r[1]):int(r[1]+r[3]), int(r[0]):int(r[0]+r[2])] = imCrop\n",
    "            if VISUALISE:\n",
    "                cv.imshow('Cropped area in its original position', img)\n",
    "                cv.waitKey()\n",
    "            if i == 0:\n",
    "                temp1 = []\n",
    "                features = cv.goodFeaturesToTrack(img, mask = None, **feature_params)\n",
    "                var = np.count_nonzero(features)\n",
    "                if  var != 2*cornerNum:\n",
    "                    i = 0\n",
    "                    pyautogui.alert(\"Try again, with a larger area. You had \"\n",
    "                                    + str(var/2) + \" out of \" + str(cornerNum) + \" feature points\"\n",
    "                                    ,title=\"Not enough corner points within ROI!\")\n",
    "                else:\n",
    "                    temp1.extend(features)\n",
    "                    i += 1\n",
    "            elif i == 1:\n",
    "                temp2 = []\n",
    "                features = cv.goodFeaturesToTrack(img, mask = None, **feature_params)\n",
    "                var = np.count_nonzero(features)\n",
    "                if var != 2*cornerNum:\n",
    "                    i = 1\n",
    "                    pyautogui.alert(\"Try again, with a larger area. You had \"\n",
    "                                    + str(var/2) + \" out of \" + str(2*cornerNum) + \" feature points\"\n",
    "                                    ,title=\"Not enough corner points within ROI!\")\n",
    "                else:\n",
    "                    temp2.extend(features)\n",
    "                    i += 1\n",
    "    rects = np.asarray(np.concatenate((temp1, temp2), axis=1)).astype(np.float32)\n",
    "    cv.destroyWindow(title)\n",
    "    cap.release()\n",
    "    return actual_frame_begin, rects\n",
    "\n",
    "\n",
    "def SaveROIsToDisk(ROI_data, frame_index, skill, user, attempt, capture):\n",
    "    path = ROIdataPath(user, attempt, skill, capture)\n",
    "    frame_index_path = path + '_frame_index.txt'\n",
    "    np.save(path, ROI_data)\n",
    "    f= open(frame_index_path,\"w+\")\n",
    "    f.write(str(frame_index))\n",
    "    f.close()\n",
    "    print('Files saved')\n",
    "    \n",
    "def getROIDataFromVideoList(vlist, skill):\n",
    "    path = root + skill + '/video/'\n",
    "    temp = {}\n",
    "    i = 0\n",
    "    v_ind = 0\n",
    "    for v in vlist:\n",
    "        v_ind += 1\n",
    "        user, attempt, capture, skill = parseFileName(v)\n",
    "        gpath = TranscriptionPath(user, attempt, skill)\n",
    "        gestureData = getGestureSeparatedFrameRanges(gpath)\n",
    "\n",
    "        input_path = path + v\n",
    "        cap = cv.VideoCapture(input_path)\n",
    "        if not cap.isOpened():\n",
    "            print('Unable to open: ' + input_path)\n",
    "            exit(0)\n",
    "\n",
    "        frame_begin = gestureData[1][0]\n",
    "        cap.set(cv.CAP_PROP_POS_FRAMES, int(frame_begin)-1)\n",
    "            \n",
    "        _, frame1 = cap.read()\n",
    "        prvs = cv.cvtColor(frame1, cv.COLOR_BGR2GRAY)\n",
    "        t = 0\n",
    "        \n",
    "        actual_frame_begin, ROIs = ChooseROIs(prvs, frame_begin, cap)\n",
    "        SaveROIsToDisk(ROIs, actual_frame_begin, skill, user, attempt, capture)\n",
    "    \n",
    "\n",
    "def CreateAndSaveROIdata(knots, needles, sutures):\n",
    "    getROIDataFromVideoList(knots, 'Knot_Tying')\n",
    "    getROIDataFromVideoList(needles, 'Needle_Passing')\n",
    "    getROIDataFromVideoList(sutures, 'Suturing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CreateAndSaveROIdata(knot_list, needle_list, suture_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
