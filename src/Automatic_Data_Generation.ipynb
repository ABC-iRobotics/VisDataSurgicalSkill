{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparse Optical Flow-based Data Generation\n",
    "A fully automatic data generation, relying on the generated ROI_data, without the need of creating the ROIs runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveRawOF = True #True for saving .mat files from the raw OF values, False for the histogram creation as before\n",
    "\n",
    "saveCSV = True #Save as CSV file instead of .mat\n",
    "\n",
    "separateGestures = False #True for Gesture Separation, False for processing each video as a whole\n",
    "\n",
    "sample_size = 30 #MAKE SURE IT'S THE SAME AS 'cornerNum' WAS WHEN THE ROI_data WAS GENERATED\n",
    "\n",
    "modes = [ \"Sparse_OF\", \"Sparse_Points\"]\n",
    "\n",
    "mode = modes[0]\n",
    "\n",
    "outfolder_root = '../data/' #The folder path for storing the .mat files\n",
    "root = '../data/JIGSAWS/' #The folder path for the JIGSAWS dataset's root\n",
    "\n",
    "\n",
    "#The actual path and filename is decided by these,\n",
    "#and in the next step created automatically if they don't yet exist\n",
    "\n",
    "if separateGestures and saveRawOF:\n",
    "    output_root = outfolder_root + 'RAW_Separate_Gestures_' + mode + '/'\n",
    "elif separateGestures:\n",
    "    output_root = outfolder_root + 'Separate_Features_' + mode + '/'\n",
    "elif saveRawOF and saveCSV:\n",
    "    output_root = root\n",
    "elif saveRawOF:\n",
    "    output_root = outfolder_root + 'RAW_' + mode + '_full_by_frames/'\n",
    "else:\n",
    "    output_root = outfolder_root + 'Global_Separate_Features_' + mode + '/'\n",
    "\n",
    "outfile_base = '2Features_' + mode + '_' # + Skill + .mat added at the function call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory  /home/gabor/Asztal/IROB/Thesis_resources/JIGSAW/  already exists\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Create directory\n",
    "dirName = output_root\n",
    "try:\n",
    "    # Create target Directory\n",
    "    os.mkdir(dirName)\n",
    "    print(\"Directory \" , dirName ,  \" Created \") \n",
    "except FileExistsError:\n",
    "    print(\"Directory \" , dirName ,  \" already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "skills = ['Knot_Tying', 'Needle_Passing', 'Suturing']\n",
    "\n",
    "\n",
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict( winSize  = (15,15),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "feature_params = dict( maxCorners = sample_size,\n",
    "                       qualityLevel = 0.3,\n",
    "                       minDistance = 7,\n",
    "                       blockSize = 7 )\n",
    "\n",
    "\n",
    "color = np.random.randint(0,255,(30,3))\n",
    "\n",
    "\n",
    "def getJIGSAWvideoTitles():\n",
    "    dir_name = root + skills[0] + '/video/'\n",
    "    knot_list = [os.path.basename(x) for x in glob.glob(dir_name+'*.avi')]\n",
    "    dir_name = root + skills[1] + '/video/'\n",
    "    needle_list = [os.path.basename(x) for x in glob.glob(dir_name+'*.avi')]\n",
    "    dir_name = root + skills[2] + '/video/'\n",
    "    suture_list = [os.path.basename(x) for x in glob.glob(dir_name+'*.avi')]\n",
    "    knot_list.sort()\n",
    "    needle_list.sort()\n",
    "    suture_list.sort()\n",
    "    return knot_list, needle_list, suture_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knot_Tying_B001_capture1.avi\n",
      "Needle_Passing_B001_capture1.avi\n",
      "Suturing_B001_capture1.avi\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "knot_list, needle_list, suture_list = getJIGSAWvideoTitles()\n",
    "print(knot_list[0])\n",
    "print(needle_list[0])\n",
    "print(suture_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getJIGSAWgestureList():\n",
    "    dir_name = root + skills[0] + '/transcriptions/'\n",
    "    trans_list = [os.path.basename(x) for x in glob.glob(dir_name+'*.txt')]\n",
    "    dir_name = root + skills[1] + '/transcriptions/'\n",
    "    trans_list.extend([os.path.basename(x) for x in glob.glob(dir_name+'*.txt')])\n",
    "    dir_name = root + skills[2] + '/transcriptions/'\n",
    "    trans_list.extend([os.path.basename(x) for x in glob.glob(dir_name+'*.txt')])\n",
    "    trans_list.sort()\n",
    "    print(len(trans_list))\n",
    "    return trans_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103\n",
      "Knot_Tying_B001.txt\n"
     ]
    }
   ],
   "source": [
    "transc_list = getJIGSAWgestureList()\n",
    "print(transc_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getROIdata(skill, user, attempt, capture):\n",
    "    base = root + skill + '/ROI_data/' + skill + '_' + user + attempt + '_' + capture\n",
    "    path = base + '.npy'\n",
    "    data = np.load(path)\n",
    "    path = base + '_frame_index.txt'\n",
    "    f = open(path, \"r\")\n",
    "    frame_ind = f.read()\n",
    "    f.close()\n",
    "    return data, frame_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseFileName(filename):\n",
    "    var = filename\n",
    "    index = 0\n",
    "    skill = var[index] #gathering skill-string\n",
    "    index += 1\n",
    "    while(var[index] != '_'):\n",
    "        skill += var[index]\n",
    "        index += 1 #finding first underscore\n",
    "    if filename[0] != 'S': #in case of Suturing there is one less underscore\n",
    "        skill += var[index]\n",
    "        index += 1\n",
    "        while(var[index] != '_'):\n",
    "            skill += var[index]\n",
    "            index += 1\n",
    "    index += 1 #skipping second underscore\n",
    "    user = var[index] #saving user_id\n",
    "    index += 1 #skipping userID\n",
    "    attempt = var[index] #first digit of attempt id\n",
    "    index += 1\n",
    "    while(var[index].isdigit()):\n",
    "        attempt += var[index]\n",
    "        index += 1\n",
    "    while(var[index] != '.'):\n",
    "        index += 1\n",
    "    capture = var[index-1] #capture_num is right before the dot\n",
    "    return  user, attempt, capture, skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGestureSeparatedFrameRanges(filename):\n",
    "    gestures = []\n",
    "    frame_begin = []\n",
    "    frame_end = []\n",
    "    with open(filename) as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            i = 0\n",
    "            temp = \"\"\n",
    "            while line[i] != ' ':\n",
    "                temp += line[i]\n",
    "                i += 1\n",
    "            frame_begin.append(int(temp)) #first characters form the beginning frames\n",
    "            temp = \"\"\n",
    "            while line[i] == ' ':\n",
    "                i += 1 #skip spaces\n",
    "            while line[i] != ' ':\n",
    "                temp += line[i]\n",
    "                i += 1\n",
    "            frame_end.append(int(temp)) #second is the end frame\n",
    "            temp = \"\"\n",
    "            while line[i] == ' ':\n",
    "                i += 1 #skip spaces\n",
    "            while line[i] != ' ' and line[i] != '\\n':\n",
    "                temp += line[i]\n",
    "                i += 1\n",
    "            gestures.append(temp)\n",
    "    output = np.vstack((np.array(gestures), np.array(frame_begin), np.array(frame_end)))\n",
    "    f.close()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TranscriptionPath(user, attempt, skill):\n",
    "    path = root + skill + '/transcriptions/'+ skill + '_' + user +  attempt + '.txt'\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optical_flow_at_given_frame_with_ROI_data(full_path, frame_begin, frame_end, p0,frame_range):\n",
    "    mean_dxs = []\n",
    "    mean_dys = []\n",
    "    raw_out = []\n",
    "    flow = p0\n",
    "    cap = cv.VideoCapture(full_path)\n",
    "    cap.set(cv.CAP_PROP_POS_FRAMES, int(frame_begin)-1)\n",
    "    ret, frame1 = cap.read()\n",
    "    if not ret:\n",
    "        print('input error at: ' + video_filename)\n",
    "        return\n",
    "    prvs = cv.cvtColor(frame1,cv.COLOR_BGR2GRAY)\n",
    "    curr_frame_num = cap.get(cv.CAP_PROP_POS_FRAMES)\n",
    "    ind = 0\n",
    "    while(int(curr_frame_num) <= int(frame_end)):\n",
    "        ret, frame2 = cap.read()\n",
    "        curr_frame_num = cap.get(cv.CAP_PROP_POS_FRAMES);\n",
    "        if not ret or (frame_range != 0 and ind == frame_range):\n",
    "            break\n",
    "\n",
    "        next = cv.cvtColor(frame2,cv.COLOR_BGR2GRAY)\n",
    "        p0_old = p0\n",
    "        p0_1 = p0[:,0,:].reshape(-1,1,2).astype(np.float32)\n",
    "        feat1_new, _, _ = cv.calcOpticalFlowPyrLK(prvs, next, p0_1, None, **lk_params)\n",
    "        p0_2 = p0[:,0,:].reshape(-1,1,2).astype(np.float32)\n",
    "        feat2_new,_,_ = cv.calcOpticalFlowPyrLK(prvs, next, p0_2, None, **lk_params)\n",
    "        prvs = next.copy()\n",
    "        p0 = np.concatenate((feat1_new, feat2_new), axis=1).astype(np.float32)\n",
    "        if mode == \"Sparse_OF\":\n",
    "            feat1_old = p0_old[:,0,:]\n",
    "            feat1_old = np.expand_dims(feat1_old, axis=1)\n",
    "            feat2_old = p0_old[:,1,:]\n",
    "            feat2_old = np.expand_dims(feat2_old, axis=1)\n",
    "            diff_1 = np.subtract(feat1_old, feat1_new)\n",
    "            diff_2 = np.subtract(feat2_old, feat2_new)\n",
    "            diff = np.asarray(np.concatenate((diff_1, diff_2), axis=1)).astype(np.float32)\n",
    "            flow = np.asarray(np.concatenate((diff, p0), axis = 2)).astype(np.float32)\n",
    "        elif mode == \"Sparse_Points\":\n",
    "            flow = p0\n",
    "\n",
    "        if saveRawOF:\n",
    "            raw_out.append(flow)\n",
    "        else:\n",
    "            dx, dy = np.reshape(np.swapaxes(flow,0,2), (2, -1))\n",
    "\n",
    "            mean_dxs.append(np.mean(dx))\n",
    "            mean_dys.append(np.mean(dy))\n",
    "        ind += 1\n",
    "\n",
    "    cap.release()\n",
    "    if saveRawOF:\n",
    "        return raw_out\n",
    "    else:\n",
    "        return mean_dxs, mean_dys, p0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractDataFromSpecificFrames(full_path, filename, gesture, frame_begin, frame_end, p0, frame_range):\n",
    "    if saveRawOF:\n",
    "        flow = get_optical_flow_at_given_frame_with_ROI_data(\n",
    "                                        full_path,frame_begin, frame_end,p0,frame_range)\n",
    "        return flow\n",
    "    else:\n",
    "        mean_dxs, mean_dys, p0 = get_optical_flow_at_given_frame_with_ROI_data(\n",
    "                                        full_path,frame_begin, frame_end,p0,frame_range)\n",
    "        x = np.array([mean_dxs])\n",
    "        y = np.array([mean_dys])\n",
    "        histo = np.hstack((np.array(x), np.array(y))).astype(np.object)\n",
    "        #print('Histogram extracted from ' + filename +\n",
    "        #      ' for gesture (' + gesture  + ') from frames: ' +str(frame_begin) + '-' + str(frame_end))\n",
    "        return histo, p0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveCSVs(skill, user, attempt, capture, data):\n",
    "    skill_short = \"short\"\n",
    "    if skill == 'Knot_Tying':\n",
    "        skill_short = 'Knot'\n",
    "    if skill == 'Needle_Passing':\n",
    "        skill_short = 'Needle'\n",
    "    if skill == 'Suturing':\n",
    "        skill_short = 'Suture'\n",
    "    filename = output_root + skill + '/video/csvs/' + skill_short + '_'\n",
    "    filename = filename +  user + '_' + attempt + '_' + capture + '.csv'\n",
    "    #data.shape = frame_numberx30x2x2\n",
    "    with open(filename, 'w', newline='') as csvfile:\n",
    "        #defining the field names,\n",
    "        #namely the 30 points of interest for the two features, and their two data members\n",
    "        #This defines the possible coloumns\n",
    "        fieldnames = [#the OF value pairs for each feature\n",
    "                      'feature_1_1_1', 'feature_1_1_2','feature_2_1_1', 'feature_2_1_2',\n",
    "                      'feature_1_2_1', 'feature_1_2_2', 'feature_2_2_1', 'feature_2_2_2',\n",
    "                      'feature_1_3_1', 'feature_1_3_2', 'feature_2_3_1', 'feature_2_3_2',\n",
    "                      'feature_1_4_1', 'feature_1_4_2', 'feature_2_4_1', 'feature_2_4_2',\n",
    "                      'feature_1_5_1', 'feature_1_5_2', 'feature_2_5_1', 'feature_2_5_2',\n",
    "                      'feature_1_6_1', 'feature_1_6_2', 'feature_2_6_1', 'feature_2_6_2',\n",
    "                      'feature_1_7_1', 'feature_1_7_2', 'feature_2_7_1', 'feature_2_7_2',\n",
    "                      'feature_1_8_1', 'feature_1_8_2', 'feature_2_8_1', 'feature_2_8_2',\n",
    "                      'feature_1_9_1', 'feature_1_9_2', 'feature_2_9_1', 'feature_2_9_2',\n",
    "                      'feature_1_10_1', 'feature_1_10_2', 'feature_2_10_1', 'feature_2_10_2',\n",
    "                      'feature_1_11_1', 'feature_1_11_2', 'feature_2_11_1', 'feature_2_11_2',\n",
    "                      'feature_1_12_1', 'feature_1_12_2', 'feature_2_12_1', 'feature_2_12_2',\n",
    "                      'feature_1_13_1', 'feature_1_13_2', 'feature_2_13_1', 'feature_2_13_2',\n",
    "                      'feature_1_14_1', 'feature_1_14_2', 'feature_2_14_1', 'feature_2_14_2',\n",
    "                      'feature_1_15_1', 'feature_1_15_2', 'feature_2_15_1', 'feature_2_15_2',\n",
    "                      'feature_1_16_1', 'feature_1_16_2', 'feature_2_16_1', 'feature_2_16_2',\n",
    "                      'feature_1_17_1', 'feature_1_17_2', 'feature_2_17_1', 'feature_2_17_2',\n",
    "                      'feature_1_18_1', 'feature_1_18_2', 'feature_2_18_1', 'feature_2_18_2',\n",
    "                      'feature_1_19_1', 'feature_1_19_2', 'feature_2_19_1', 'feature_2_19_2',\n",
    "                      'feature_1_20_1', 'feature_1_20_2', 'feature_2_20_1', 'feature_2_20_2',\n",
    "                      'feature_1_21_1', 'feature_1_21_2', 'feature_2_21_1', 'feature_2_21_2',\n",
    "                      'feature_1_22_1', 'feature_1_22_2', 'feature_2_22_1', 'feature_2_22_2',\n",
    "                      'feature_1_23_1', 'feature_1_23_2', 'feature_2_23_1', 'feature_2_23_2',\n",
    "                      'feature_1_24_1', 'feature_1_24_2', 'feature_2_24_1', 'feature_2_24_2',\n",
    "                      'feature_1_25_1', 'feature_1_25_2', 'feature_2_25_1', 'feature_2_25_2',\n",
    "                      'feature_1_26_1', 'feature_1_26_2', 'feature_2_26_1', 'feature_2_26_2',\n",
    "                      'feature_1_27_1', 'feature_1_27_2', 'feature_2_27_1', 'feature_2_27_2',\n",
    "                      'feature_1_28_1', 'feature_1_28_2', 'feature_2_28_1', 'feature_2_28_2',\n",
    "                      'feature_1_29_1', 'feature_1_29_2', 'feature_2_29_1', 'feature_2_29_2',\n",
    "                      'feature_1_30_1', 'feature_1_30_2', 'feature_2_30_1', 'feature_2_30_2',\n",
    "                       #The tracked position values (x,y coordinates) of each feature\n",
    "                      'pos_1_1_1', 'pos_1_1_2','pos_2_1_1', 'pos_2_1_2',\n",
    "                      'pos_1_2_1', 'pos_1_2_2', 'pos_2_2_1', 'pos_2_2_2',\n",
    "                      'pos_1_3_1', 'pos_1_3_2', 'pos_2_3_1', 'pos_2_3_2',\n",
    "                      'pos_1_4_1', 'pos_1_4_2', 'pos_2_4_1', 'pos_2_4_2',\n",
    "                      'pos_1_5_1', 'pos_1_5_2', 'pos_2_5_1', 'pos_2_5_2',\n",
    "                      'pos_1_6_1', 'pos_1_6_2', 'pos_2_6_1', 'pos_2_6_2',\n",
    "                      'pos_1_7_1', 'pos_1_7_2', 'pos_2_7_1', 'pos_2_7_2',\n",
    "                      'pos_1_8_1', 'pos_1_8_2', 'pos_2_8_1', 'pos_2_8_2',\n",
    "                      'pos_1_9_1', 'pos_1_9_2', 'pos_2_9_1', 'pos_2_9_2',\n",
    "                      'pos_1_10_1', 'pos_1_10_2', 'pos_2_10_1', 'pos_2_10_2',\n",
    "                      'pos_1_11_1', 'pos_1_11_2', 'pos_2_11_1', 'pos_2_11_2',\n",
    "                      'pos_1_12_1', 'pos_1_12_2', 'pos_2_12_1', 'pos_2_12_2',\n",
    "                      'pos_1_13_1', 'pos_1_13_2', 'pos_2_13_1', 'pos_2_13_2',\n",
    "                      'pos_1_14_1', 'pos_1_14_2', 'pos_2_14_1', 'pos_2_14_2',\n",
    "                      'pos_1_15_1', 'pos_1_15_2', 'pos_2_15_1', 'pos_2_15_2',\n",
    "                      'pos_1_16_1', 'pos_1_16_2', 'pos_2_16_1', 'pos_2_16_2',\n",
    "                      'pos_1_17_1', 'pos_1_17_2', 'pos_2_17_1', 'pos_2_17_2',\n",
    "                      'pos_1_18_1', 'pos_1_18_2', 'pos_2_18_1', 'pos_2_18_2',\n",
    "                      'pos_1_19_1', 'pos_1_19_2', 'pos_2_19_1', 'pos_2_19_2',\n",
    "                      'pos_1_20_1', 'pos_1_20_2', 'pos_2_20_1', 'pos_2_20_2',\n",
    "                      'pos_1_21_1', 'pos_1_21_2', 'pos_2_21_1', 'pos_2_21_2',\n",
    "                      'pos_1_22_1', 'pos_1_22_2', 'pos_2_22_1', 'pos_2_22_2',\n",
    "                      'pos_1_23_1', 'pos_1_23_2', 'pos_2_23_1', 'pos_2_23_2',\n",
    "                      'pos_1_24_1', 'pos_1_24_2', 'pos_2_24_1', 'pos_2_24_2',\n",
    "                      'pos_1_25_1', 'pos_1_25_2', 'pos_2_25_1', 'pos_2_25_2',\n",
    "                      'pos_1_26_1', 'pos_1_26_2', 'pos_2_26_1', 'pos_2_26_2',\n",
    "                      'pos_1_27_1', 'pos_1_27_2', 'pos_2_27_1', 'pos_2_27_2',\n",
    "                      'pos_1_28_1', 'pos_1_28_2', 'pos_2_28_1', 'pos_2_28_2',\n",
    "                      'pos_1_29_1', 'pos_1_29_2', 'pos_2_29_1', 'pos_2_29_2',\n",
    "                      'pos_1_30_1', 'pos_1_30_2', 'pos_2_30_1', 'pos_2_30_2'\n",
    "                     ]\n",
    "        writer = csv.DictWriter(csvfile,fieldnames=fieldnames)\n",
    "        #writer.writeheader() #uncomment if you want to include the coloumn titles in the first row\n",
    "        for d in data: #30x2x4 (now also containing the coordinates/position info)\n",
    "            #create a temporary dictionary for the given frame's data\n",
    "            #This basically creates the datarow, by order of the coloumns\n",
    "            temp = {\n",
    "            #OF values of the first feature (tool_1)\n",
    "            'feature_1_1_1': d[0][0][0], 'feature_1_1_2': d[0][0][1],\n",
    "            'feature_1_2_1': d[1][0][0], 'feature_1_2_2': d[1][0][1],\n",
    "            'feature_1_3_1': d[2][0][0], 'feature_1_3_2': d[2][0][1],\n",
    "            'feature_1_4_1': d[3][0][0], 'feature_1_4_2': d[3][0][1],\n",
    "            'feature_1_5_1': d[4][0][0], 'feature_1_5_2': d[4][0][1],\n",
    "            'feature_1_6_1': d[5][0][0], 'feature_1_6_2': d[5][0][1],\n",
    "            'feature_1_7_1': d[6][0][0], 'feature_1_7_2': d[6][0][1],\n",
    "            'feature_1_8_1': d[7][0][0], 'feature_1_8_2': d[7][0][1],\n",
    "            'feature_1_9_1': d[8][0][0], 'feature_1_9_2': d[8][0][1],\n",
    "            'feature_1_10_1': d[9][0][0], 'feature_1_10_2': d[9][0][1],\n",
    "            'feature_1_11_1': d[10][0][0], 'feature_1_11_2': d[10][0][1],\n",
    "            'feature_1_12_1': d[11][0][0], 'feature_1_12_2': d[11][0][1],\n",
    "            'feature_1_13_1': d[12][0][0], 'feature_1_13_2': d[12][0][1],\n",
    "            'feature_1_14_1': d[13][0][0], 'feature_1_14_2': d[13][0][1],\n",
    "            'feature_1_15_1': d[14][0][0], 'feature_1_15_2': d[14][0][1],\n",
    "            'feature_1_16_1': d[15][0][0], 'feature_1_16_2': d[15][0][1],\n",
    "            'feature_1_17_1': d[16][0][0], 'feature_1_17_2': d[16][0][1],\n",
    "            'feature_1_18_1': d[17][0][0], 'feature_1_18_2': d[17][0][1],\n",
    "            'feature_1_19_1': d[18][0][0], 'feature_1_19_2': d[18][0][1],\n",
    "            'feature_1_20_1': d[19][0][0], 'feature_1_20_2': d[19][0][1],\n",
    "            'feature_1_21_1': d[20][0][0], 'feature_1_21_2': d[20][0][1],\n",
    "            'feature_1_22_1': d[21][0][0], 'feature_1_22_2': d[21][0][1],\n",
    "            'feature_1_23_1': d[22][0][0], 'feature_1_23_2': d[22][0][1],\n",
    "            'feature_1_24_1': d[23][0][0], 'feature_1_24_2': d[23][0][1],\n",
    "            'feature_1_25_1': d[24][0][0], 'feature_1_25_2': d[24][0][1],\n",
    "            'feature_1_26_1': d[25][0][0], 'feature_1_26_2': d[25][0][1],\n",
    "            'feature_1_27_1': d[26][0][0], 'feature_1_27_2': d[26][0][1],\n",
    "            'feature_1_28_1': d[27][0][0], 'feature_1_28_2': d[27][0][1],\n",
    "            'feature_1_29_1': d[28][0][0], 'feature_1_29_2': d[28][0][1],\n",
    "            'feature_1_30_1': d[29][0][0], 'feature_1_30_2': d[29][0][1],\n",
    "            #Coordinates of the first feature (tool_1)\n",
    "            'pos_1_1_1': d[0][0][2], 'pos_1_1_2': d[0][0][3],\n",
    "            'pos_1_2_1': d[1][0][2], 'pos_1_2_2': d[1][0][3],\n",
    "            'pos_1_3_1': d[2][0][2], 'pos_1_3_2': d[2][0][3],\n",
    "            'pos_1_4_1': d[3][0][2], 'pos_1_4_2': d[3][0][3],\n",
    "            'pos_1_5_1': d[4][0][2], 'pos_1_5_2': d[4][0][3],\n",
    "            'pos_1_6_1': d[5][0][2], 'pos_1_6_2': d[5][0][3],\n",
    "            'pos_1_7_1': d[6][0][2], 'pos_1_7_2': d[6][0][3],\n",
    "            'pos_1_8_1': d[7][0][2], 'pos_1_8_2': d[7][0][3],\n",
    "            'pos_1_9_1': d[8][0][2], 'pos_1_9_2': d[8][0][3],\n",
    "            'pos_1_10_1': d[9][0][2], 'pos_1_10_2': d[9][0][3],\n",
    "            'pos_1_11_1': d[10][0][2], 'pos_1_11_2': d[10][0][3],\n",
    "            'pos_1_12_1': d[11][0][2], 'pos_1_12_2': d[11][0][3],\n",
    "            'pos_1_13_1': d[12][0][2], 'pos_1_13_2': d[12][0][3],\n",
    "            'pos_1_14_1': d[13][0][2], 'pos_1_14_2': d[13][0][3],\n",
    "            'pos_1_15_1': d[14][0][2], 'pos_1_15_2': d[14][0][3],\n",
    "            'pos_1_16_1': d[15][0][2], 'pos_1_16_2': d[15][0][3],\n",
    "            'pos_1_17_1': d[16][0][2], 'pos_1_17_2': d[16][0][3],\n",
    "            'pos_1_18_1': d[17][0][2], 'pos_1_18_2': d[17][0][3],\n",
    "            'pos_1_19_1': d[18][0][2], 'pos_1_19_2': d[18][0][3],\n",
    "            'pos_1_20_1': d[19][0][2], 'pos_1_20_2': d[19][0][3],\n",
    "            'pos_1_21_1': d[20][0][2], 'pos_1_21_2': d[20][0][3],\n",
    "            'pos_1_22_1': d[21][0][2], 'pos_1_22_2': d[21][0][3],\n",
    "            'pos_1_23_1': d[22][0][2], 'pos_1_23_2': d[22][0][3],\n",
    "            'pos_1_24_1': d[23][0][2], 'pos_1_24_2': d[23][0][3],\n",
    "            'pos_1_25_1': d[24][0][2], 'pos_1_25_2': d[24][0][3],\n",
    "            'pos_1_26_1': d[25][0][2], 'pos_1_26_2': d[25][0][3],\n",
    "            'pos_1_27_1': d[26][0][2], 'pos_1_27_2': d[26][0][3],\n",
    "            'pos_1_28_1': d[27][0][2], 'pos_1_28_2': d[27][0][3],\n",
    "            'pos_1_29_1': d[28][0][2], 'pos_1_29_2': d[28][0][3],\n",
    "            'pos_1_30_1': d[29][0][2], 'pos_1_30_2': d[29][0][3],\n",
    "            #OF values of the second feature (tool_2)\n",
    "            'feature_2_1_1': d[0][1][0], 'feature_2_1_2': d[0][1][1],\n",
    "            'feature_2_2_1': d[1][1][0], 'feature_2_2_2': d[1][1][1],\n",
    "            'feature_2_3_1': d[2][1][0], 'feature_2_3_2': d[2][1][1],\n",
    "            'feature_2_4_1': d[3][1][0], 'feature_2_4_2': d[3][1][1],\n",
    "            'feature_2_5_1': d[4][1][0], 'feature_2_5_2': d[4][1][1],\n",
    "            'feature_2_6_1': d[5][1][0], 'feature_2_6_2': d[5][1][1],\n",
    "            'feature_2_7_1': d[6][1][0], 'feature_2_7_2': d[6][1][1],\n",
    "            'feature_2_8_1': d[7][1][0], 'feature_2_8_2': d[7][1][1],\n",
    "            'feature_2_9_1': d[8][1][0], 'feature_2_9_2': d[8][1][1],\n",
    "            'feature_2_10_1': d[9][1][0], 'feature_2_10_2': d[9][1][1],\n",
    "            'feature_2_11_1': d[10][1][0], 'feature_2_11_2': d[10][1][1],\n",
    "            'feature_2_12_1': d[11][1][0], 'feature_2_12_2': d[11][1][1],\n",
    "            'feature_2_13_1': d[12][1][0], 'feature_2_13_2': d[12][1][1],\n",
    "            'feature_2_14_1': d[13][1][0], 'feature_2_14_2': d[13][1][1],\n",
    "            'feature_2_15_1': d[14][1][0], 'feature_2_15_2': d[14][1][1],\n",
    "            'feature_2_16_1': d[15][1][0], 'feature_2_16_2': d[15][1][1],\n",
    "            'feature_2_17_1': d[16][1][0], 'feature_2_17_2': d[16][1][1],\n",
    "            'feature_2_18_1': d[17][1][0], 'feature_2_18_2': d[17][1][1],\n",
    "            'feature_2_19_1': d[18][1][0], 'feature_2_19_2': d[18][1][1],\n",
    "            'feature_2_20_1': d[19][1][0], 'feature_2_20_2': d[19][1][1],\n",
    "            'feature_2_21_1': d[20][1][0], 'feature_2_21_2': d[20][1][1],\n",
    "            'feature_2_22_1': d[21][1][0], 'feature_2_22_2': d[21][1][1],\n",
    "            'feature_2_23_1': d[22][1][0], 'feature_2_23_2': d[22][1][1],\n",
    "            'feature_2_24_1': d[23][1][0], 'feature_2_24_2': d[23][1][1],\n",
    "            'feature_2_25_1': d[24][1][0], 'feature_2_25_2': d[24][1][1],\n",
    "            'feature_2_26_1': d[25][1][0], 'feature_2_26_2': d[25][1][1],\n",
    "            'feature_2_27_1': d[26][1][0], 'feature_2_27_2': d[26][1][1],\n",
    "            'feature_2_28_1': d[27][1][0], 'feature_2_28_2': d[27][1][1],\n",
    "            'feature_2_29_1': d[28][1][0], 'feature_2_29_2': d[28][1][1],\n",
    "            'feature_2_30_1': d[29][1][0], 'feature_2_30_2': d[29][1][1],\n",
    "             #coordinates of the second feature (tool_2)\n",
    "            'pos_2_1_1': d[0][1][2], 'pos_2_1_2': d[0][1][3],\n",
    "            'pos_2_2_1': d[1][1][2], 'pos_2_2_2': d[1][1][3],\n",
    "            'pos_2_3_1': d[2][1][2], 'pos_2_3_2': d[2][1][3],\n",
    "            'pos_2_4_1': d[3][1][2], 'pos_2_4_2': d[3][1][3],\n",
    "            'pos_2_5_1': d[4][1][2], 'pos_2_5_2': d[4][1][3],\n",
    "            'pos_2_6_1': d[5][1][2], 'pos_2_6_2': d[5][1][3],\n",
    "            'pos_2_7_1': d[6][1][2], 'pos_2_7_2': d[6][1][3],\n",
    "            'pos_2_8_1': d[7][1][2], 'pos_2_8_2': d[7][1][3],\n",
    "            'pos_2_9_1': d[8][1][2], 'pos_2_9_2': d[8][1][3],\n",
    "            'pos_2_10_1': d[9][1][2], 'pos_2_10_2': d[9][1][3],\n",
    "            'pos_2_11_1': d[10][1][2], 'pos_2_11_2': d[10][1][3],\n",
    "            'pos_2_12_1': d[11][1][2], 'pos_2_12_2': d[11][1][3],\n",
    "            'pos_2_13_1': d[12][1][2], 'pos_2_13_2': d[12][1][3],\n",
    "            'pos_2_14_1': d[13][1][2], 'pos_2_14_2': d[13][1][3],\n",
    "            'pos_2_15_1': d[14][1][2], 'pos_2_15_2': d[14][1][3],\n",
    "            'pos_2_16_1': d[15][1][2], 'pos_2_16_2': d[15][1][3],\n",
    "            'pos_2_17_1': d[16][1][2], 'pos_2_17_2': d[16][1][3],\n",
    "            'pos_2_18_1': d[17][1][2], 'pos_2_18_2': d[17][1][3],\n",
    "            'pos_2_19_1': d[18][1][2], 'pos_2_19_2': d[18][1][3],\n",
    "            'pos_2_20_1': d[19][1][2], 'pos_2_20_2': d[19][1][3],\n",
    "            'pos_2_21_1': d[20][1][2], 'pos_2_21_2': d[20][1][3],\n",
    "            'pos_2_22_1': d[21][1][2], 'pos_2_22_2': d[21][1][3],\n",
    "            'pos_2_23_1': d[22][1][2], 'pos_2_23_2': d[22][1][3],\n",
    "            'pos_2_24_1': d[23][1][2], 'pos_2_24_2': d[23][1][3],\n",
    "            'pos_2_25_1': d[24][1][2], 'pos_2_25_2': d[24][1][3],\n",
    "            'pos_2_26_1': d[25][1][2], 'pos_2_26_2': d[25][1][3],\n",
    "            'pos_2_27_1': d[26][1][2], 'pos_2_27_2': d[26][1][3],\n",
    "            'pos_2_28_1': d[27][1][2], 'pos_2_28_2': d[27][1][3],\n",
    "            'pos_2_29_1': d[28][1][2], 'pos_2_29_2': d[28][1][3],\n",
    "            'pos_2_30_1': d[29][1][2], 'pos_2_30_2': d[29][1][3],\n",
    "            }\n",
    "            #and add that to the csv as a row ->resulting in as many rows as frames\n",
    "            writer.writerow(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "novice_list = { 'B', 'G', 'H', 'I'}\n",
    "interm_list = { 'C', 'F'}\n",
    "expert_list = { 'D', 'E'}\n",
    "import csv\n",
    "\n",
    "def saveRawDataAccordingToExpertise(novices, interms, experts, user, attempt,data, novice_ind, interm_ind, expert_ind):\n",
    "    if data == []:\n",
    "        return novices, interms, experts, novice_ind, interm_ind, expert_ind\n",
    "    if user in novice_list:\n",
    "        novices[novice_ind] = np.array([\n",
    "            {\n",
    "                'data': data,\n",
    "                'userid': user,\n",
    "                'attemptid':attempt\n",
    "            }\n",
    "        ])\n",
    "        novice_ind += 1\n",
    "    if user in interm_list:\n",
    "        interms[interm_ind] = np.array([\n",
    "            {\n",
    "                'data': data,\n",
    "                'userid': user,\n",
    "                'attemptid':attempt\n",
    "            }\n",
    "        ])\n",
    "        interm_ind += 1\n",
    "    if user in expert_list:\n",
    "        experts[expert_ind] = np.array([\n",
    "            {\n",
    "                'data': data,\n",
    "                'userid': user,\n",
    "                'attemptid':attempt\n",
    "            }\n",
    "        ])\n",
    "        expert_ind += 1\n",
    "    return novices, interms, experts, novice_ind, interm_ind, expert_ind\n",
    "\n",
    "\n",
    "def getMinFrameRange(data): #not used, too much data loss\n",
    "    val = int(data[2][0]) - int(data[1][0])\n",
    "    for i in range(len(data[0])):\n",
    "        diff = int(data[2][i]) - int(data[1][i])\n",
    "        if diff < val:\n",
    "            val = diff\n",
    "    return val\n",
    "            \n",
    "def extractDataFromVideoList(vlist, skill):\n",
    "    path = root + skill + '/video/'\n",
    "    temp = {}\n",
    "    novices = {}\n",
    "    interms = {}\n",
    "    experts = {}\n",
    "    novice_ind, interm_ind, expert_ind = 0,0,0\n",
    "    i = 0\n",
    "    v_ind = 0\n",
    "    for v in vlist:\n",
    "        v_ind += 1\n",
    "        user, attempt, capture, skill = parseFileName(v)\n",
    "        input_path = path + v\n",
    "        cap = cv.VideoCapture(input_path)\n",
    "        if not cap.isOpened():\n",
    "            print('Unable to open: ' + input_path)\n",
    "            exit(0)\n",
    "\n",
    "        p0, actual_frame_begin = getROIdata(skill, user, attempt, capture)\n",
    "\n",
    "        _, frame1 = cap.read()\n",
    "        prvs = cv.cvtColor(frame1, cv.COLOR_BGR2GRAY)\n",
    "        cap.release()\n",
    "        if separateGestures:\n",
    "            gpath = TranscriptionPath(user, attempt, skill)\n",
    "            gestureData = getGestureSeparatedFrameRanges(gpath)\n",
    "            min_frame_range = getMinFrameRange(gestureData)\n",
    "            for g_ind in range(len(gestureData[0])):\n",
    "                gesture = gestureData[0][g_ind]\n",
    "                if g_ind == 0:\n",
    "                    frame_begin = actual_frame_begin\n",
    "                else:\n",
    "                    frame_begin = gestureData[1][g_ind]\n",
    "                frame_end = gestureData[2][g_ind]\n",
    "                if saveRawOF:\n",
    "                    flow = extractDataFromSpecificFrames(path + v, v, gesture,frame_begin, frame_end, p0, min_frame_range)\n",
    "                    if saveCSV:\n",
    "                        saveCSVs(skill, user, attempt, capture, flow)\n",
    "                    else:\n",
    "                        #for f in flow:\n",
    "                        #    novices, interms, experts, novice_ind, interm_ind, expert_ind = saveRawDataAccordingToExpertise(novices, interms, experts, user, attempt,f, novice_ind, interm_ind, expert_ind)\n",
    "                        novices, interms, experts, novice_ind, interm_ind, expert_ind = saveRawDataAccordingToExpertise(novices, interms, experts, user, attempt,flow, novice_ind, interm_ind, expert_ind)\n",
    "                else:\n",
    "                    histo, p0 = extractDataFromSpecificFrames(path + v, v, gesture,frame_begin, frame_end, p0)\n",
    "                    temp[i] = np.array([\n",
    "                        {'user': str(user),\n",
    "                         'attempt_id': attempt,\n",
    "                         'data':histo,\n",
    "                         'gesture':str(gesture),\n",
    "                        }], dtype=np.object)\n",
    "        else:\n",
    "            cap = cv.VideoCapture(input_path)\n",
    "            frame_end = int(cap.get(cv.CAP_PROP_FRAME_COUNT))\n",
    "            if saveRawOF:\n",
    "                flow = extractDataFromSpecificFrames(path + v, v, \"no_gesture\", actual_frame_begin, frame_end, p0, 0)\n",
    "                if saveCSV:\n",
    "                    saveCSVs(skill, user, attempt, capture, flow)\n",
    "                else:\n",
    "                    #for f in flow:\n",
    "                    #   novices, interms, experts, novice_ind, interm_ind, expert_ind = saveRawDataAccordingToExpertise(novices, interms, experts, user, attempt,f, novice_ind, interm_ind, expert_ind)\n",
    "                    novices, interms, experts, novice_ind, interm_ind, expert_ind = saveRawDataAccordingToExpertise(novices, interms, experts, user, attempt,flow, novice_ind, interm_ind, expert_ind)\n",
    "            else:\n",
    "                histo, p0 = extractDataFromSpecificFrames(path + v, v, \"no_gesture\", actual_frame_begin, frame_end, p0, 0)\n",
    "                temp[i] = np.array([\n",
    "                    {'user': str(user),\n",
    "                     'attempt_id': attempt,\n",
    "                     'data':histo}], dtype=np.object)\n",
    "        i += 1\n",
    "        print(str(v_ind) +' out of '+ str(len(vlist))+' videos processed, grouped and stored...')\n",
    "\n",
    "    if saveRawOF and not saveCSV:\n",
    "        output = {}\n",
    "        output[1] = np.array(list(novices.items()))\n",
    "        output[2] = np.array(list(interms.items()))\n",
    "        output[3] = np.array(list(experts.items()))\n",
    "        return{'dataX': list(output.items())}\n",
    "    elif not saveRawOF:\n",
    "         return{'dataA': list(temp.items())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io as sio\n",
    "def writeMatFile(dictionary, filename):\n",
    "    if saveRawOF:\n",
    "        path = output_root + filename + '_dataX_basic_' + str(180) + '_' + str(60) + '.mat'\n",
    "        sio.savemat(path, dictionary)\n",
    "    else:\n",
    "        path = output_root + filename\n",
    "        sio.savemat(path, dictionary)\n",
    "    print(path + ' written')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createNestedDictionariesPerGestures(knots, needles, sutures):\n",
    "    if saveRawOF:\n",
    "        knot_dic = extractDataFromVideoList(knots, 'Knot_Tying')\n",
    "        if not saveCSV:\n",
    "            writeMatFile(knot_dic,'Knot')\n",
    "        needle_dic = extractDataFromVideoList(needles, 'Needle_Passing')\n",
    "        if not saveCSV:\n",
    "            writeMatFile(needle_dic, 'Needle')\n",
    "        suture_dic = extractDataFromVideoList(sutures, 'Suturing')\n",
    "        if not saveCSV:\n",
    "            writeMatFile(suture_dic, 'Suture')  \n",
    "    else:\n",
    "        knot_dic = extractDataFromVideoList(knots, 'Knot_Tying')\n",
    "        writeMatFile(knot_dic, outfile_base + 'Knot.mat')\n",
    "        needle_dic = extractDataFromVideoList(needles, 'Needle_Passing')\n",
    "        writeMatFile(needle_dic, outfile_base + 'Needle.mat')\n",
    "        suture_dic = extractDataFromVideoList(sutures, 'Suturing')\n",
    "        writeMatFile(suture_dic, outfile_base + 'Suture.mat')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 out of 72 videos processed, grouped and stored...\n",
      "2 out of 72 videos processed, grouped and stored...\n",
      "3 out of 72 videos processed, grouped and stored...\n",
      "4 out of 72 videos processed, grouped and stored...\n",
      "5 out of 72 videos processed, grouped and stored...\n",
      "6 out of 72 videos processed, grouped and stored...\n",
      "7 out of 72 videos processed, grouped and stored...\n",
      "8 out of 72 videos processed, grouped and stored...\n",
      "9 out of 72 videos processed, grouped and stored...\n",
      "10 out of 72 videos processed, grouped and stored...\n",
      "11 out of 72 videos processed, grouped and stored...\n",
      "12 out of 72 videos processed, grouped and stored...\n",
      "13 out of 72 videos processed, grouped and stored...\n",
      "14 out of 72 videos processed, grouped and stored...\n",
      "15 out of 72 videos processed, grouped and stored...\n",
      "16 out of 72 videos processed, grouped and stored...\n",
      "17 out of 72 videos processed, grouped and stored...\n",
      "18 out of 72 videos processed, grouped and stored...\n",
      "19 out of 72 videos processed, grouped and stored...\n",
      "20 out of 72 videos processed, grouped and stored...\n",
      "21 out of 72 videos processed, grouped and stored...\n",
      "22 out of 72 videos processed, grouped and stored...\n",
      "23 out of 72 videos processed, grouped and stored...\n",
      "24 out of 72 videos processed, grouped and stored...\n",
      "25 out of 72 videos processed, grouped and stored...\n",
      "26 out of 72 videos processed, grouped and stored...\n",
      "27 out of 72 videos processed, grouped and stored...\n",
      "28 out of 72 videos processed, grouped and stored...\n",
      "29 out of 72 videos processed, grouped and stored...\n",
      "30 out of 72 videos processed, grouped and stored...\n",
      "31 out of 72 videos processed, grouped and stored...\n",
      "32 out of 72 videos processed, grouped and stored...\n",
      "33 out of 72 videos processed, grouped and stored...\n",
      "34 out of 72 videos processed, grouped and stored...\n",
      "35 out of 72 videos processed, grouped and stored...\n",
      "36 out of 72 videos processed, grouped and stored...\n",
      "37 out of 72 videos processed, grouped and stored...\n",
      "38 out of 72 videos processed, grouped and stored...\n",
      "39 out of 72 videos processed, grouped and stored...\n",
      "40 out of 72 videos processed, grouped and stored...\n",
      "41 out of 72 videos processed, grouped and stored...\n",
      "42 out of 72 videos processed, grouped and stored...\n",
      "43 out of 72 videos processed, grouped and stored...\n",
      "44 out of 72 videos processed, grouped and stored...\n",
      "45 out of 72 videos processed, grouped and stored...\n",
      "46 out of 72 videos processed, grouped and stored...\n",
      "47 out of 72 videos processed, grouped and stored...\n",
      "48 out of 72 videos processed, grouped and stored...\n",
      "49 out of 72 videos processed, grouped and stored...\n",
      "50 out of 72 videos processed, grouped and stored...\n",
      "51 out of 72 videos processed, grouped and stored...\n",
      "52 out of 72 videos processed, grouped and stored...\n",
      "53 out of 72 videos processed, grouped and stored...\n",
      "54 out of 72 videos processed, grouped and stored...\n",
      "55 out of 72 videos processed, grouped and stored...\n",
      "56 out of 72 videos processed, grouped and stored...\n",
      "57 out of 72 videos processed, grouped and stored...\n",
      "58 out of 72 videos processed, grouped and stored...\n",
      "59 out of 72 videos processed, grouped and stored...\n",
      "60 out of 72 videos processed, grouped and stored...\n",
      "61 out of 72 videos processed, grouped and stored...\n",
      "62 out of 72 videos processed, grouped and stored...\n",
      "63 out of 72 videos processed, grouped and stored...\n",
      "64 out of 72 videos processed, grouped and stored...\n",
      "65 out of 72 videos processed, grouped and stored...\n",
      "66 out of 72 videos processed, grouped and stored...\n",
      "67 out of 72 videos processed, grouped and stored...\n",
      "68 out of 72 videos processed, grouped and stored...\n",
      "69 out of 72 videos processed, grouped and stored...\n",
      "70 out of 72 videos processed, grouped and stored...\n",
      "71 out of 72 videos processed, grouped and stored...\n",
      "72 out of 72 videos processed, grouped and stored...\n",
      "1 out of 56 videos processed, grouped and stored...\n",
      "2 out of 56 videos processed, grouped and stored...\n",
      "3 out of 56 videos processed, grouped and stored...\n",
      "4 out of 56 videos processed, grouped and stored...\n",
      "5 out of 56 videos processed, grouped and stored...\n",
      "6 out of 56 videos processed, grouped and stored...\n",
      "7 out of 56 videos processed, grouped and stored...\n",
      "8 out of 56 videos processed, grouped and stored...\n",
      "9 out of 56 videos processed, grouped and stored...\n",
      "10 out of 56 videos processed, grouped and stored...\n",
      "11 out of 56 videos processed, grouped and stored...\n",
      "12 out of 56 videos processed, grouped and stored...\n",
      "13 out of 56 videos processed, grouped and stored...\n",
      "14 out of 56 videos processed, grouped and stored...\n",
      "15 out of 56 videos processed, grouped and stored...\n",
      "16 out of 56 videos processed, grouped and stored...\n",
      "17 out of 56 videos processed, grouped and stored...\n",
      "18 out of 56 videos processed, grouped and stored...\n",
      "19 out of 56 videos processed, grouped and stored...\n",
      "20 out of 56 videos processed, grouped and stored...\n",
      "21 out of 56 videos processed, grouped and stored...\n",
      "22 out of 56 videos processed, grouped and stored...\n",
      "23 out of 56 videos processed, grouped and stored...\n",
      "24 out of 56 videos processed, grouped and stored...\n",
      "25 out of 56 videos processed, grouped and stored...\n",
      "26 out of 56 videos processed, grouped and stored...\n",
      "27 out of 56 videos processed, grouped and stored...\n",
      "28 out of 56 videos processed, grouped and stored...\n",
      "29 out of 56 videos processed, grouped and stored...\n",
      "30 out of 56 videos processed, grouped and stored...\n",
      "31 out of 56 videos processed, grouped and stored...\n",
      "32 out of 56 videos processed, grouped and stored...\n",
      "33 out of 56 videos processed, grouped and stored...\n",
      "34 out of 56 videos processed, grouped and stored...\n",
      "35 out of 56 videos processed, grouped and stored...\n",
      "36 out of 56 videos processed, grouped and stored...\n",
      "37 out of 56 videos processed, grouped and stored...\n",
      "38 out of 56 videos processed, grouped and stored...\n",
      "39 out of 56 videos processed, grouped and stored...\n",
      "40 out of 56 videos processed, grouped and stored...\n",
      "41 out of 56 videos processed, grouped and stored...\n",
      "42 out of 56 videos processed, grouped and stored...\n",
      "43 out of 56 videos processed, grouped and stored...\n",
      "44 out of 56 videos processed, grouped and stored...\n",
      "45 out of 56 videos processed, grouped and stored...\n",
      "46 out of 56 videos processed, grouped and stored...\n",
      "47 out of 56 videos processed, grouped and stored...\n",
      "48 out of 56 videos processed, grouped and stored...\n",
      "49 out of 56 videos processed, grouped and stored...\n",
      "50 out of 56 videos processed, grouped and stored...\n",
      "51 out of 56 videos processed, grouped and stored...\n",
      "52 out of 56 videos processed, grouped and stored...\n",
      "53 out of 56 videos processed, grouped and stored...\n",
      "54 out of 56 videos processed, grouped and stored...\n",
      "55 out of 56 videos processed, grouped and stored...\n",
      "56 out of 56 videos processed, grouped and stored...\n",
      "1 out of 78 videos processed, grouped and stored...\n",
      "2 out of 78 videos processed, grouped and stored...\n",
      "3 out of 78 videos processed, grouped and stored...\n",
      "4 out of 78 videos processed, grouped and stored...\n",
      "5 out of 78 videos processed, grouped and stored...\n",
      "6 out of 78 videos processed, grouped and stored...\n",
      "7 out of 78 videos processed, grouped and stored...\n",
      "8 out of 78 videos processed, grouped and stored...\n",
      "9 out of 78 videos processed, grouped and stored...\n",
      "10 out of 78 videos processed, grouped and stored...\n",
      "11 out of 78 videos processed, grouped and stored...\n",
      "12 out of 78 videos processed, grouped and stored...\n",
      "13 out of 78 videos processed, grouped and stored...\n",
      "14 out of 78 videos processed, grouped and stored...\n",
      "15 out of 78 videos processed, grouped and stored...\n",
      "16 out of 78 videos processed, grouped and stored...\n",
      "17 out of 78 videos processed, grouped and stored...\n",
      "18 out of 78 videos processed, grouped and stored...\n",
      "19 out of 78 videos processed, grouped and stored...\n",
      "20 out of 78 videos processed, grouped and stored...\n",
      "21 out of 78 videos processed, grouped and stored...\n",
      "22 out of 78 videos processed, grouped and stored...\n",
      "23 out of 78 videos processed, grouped and stored...\n",
      "24 out of 78 videos processed, grouped and stored...\n",
      "25 out of 78 videos processed, grouped and stored...\n",
      "26 out of 78 videos processed, grouped and stored...\n",
      "27 out of 78 videos processed, grouped and stored...\n",
      "28 out of 78 videos processed, grouped and stored...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 out of 78 videos processed, grouped and stored...\n",
      "30 out of 78 videos processed, grouped and stored...\n",
      "31 out of 78 videos processed, grouped and stored...\n",
      "32 out of 78 videos processed, grouped and stored...\n",
      "33 out of 78 videos processed, grouped and stored...\n",
      "34 out of 78 videos processed, grouped and stored...\n",
      "35 out of 78 videos processed, grouped and stored...\n",
      "36 out of 78 videos processed, grouped and stored...\n",
      "37 out of 78 videos processed, grouped and stored...\n",
      "38 out of 78 videos processed, grouped and stored...\n",
      "39 out of 78 videos processed, grouped and stored...\n",
      "40 out of 78 videos processed, grouped and stored...\n",
      "41 out of 78 videos processed, grouped and stored...\n",
      "42 out of 78 videos processed, grouped and stored...\n",
      "43 out of 78 videos processed, grouped and stored...\n",
      "44 out of 78 videos processed, grouped and stored...\n",
      "45 out of 78 videos processed, grouped and stored...\n",
      "46 out of 78 videos processed, grouped and stored...\n",
      "47 out of 78 videos processed, grouped and stored...\n",
      "48 out of 78 videos processed, grouped and stored...\n",
      "49 out of 78 videos processed, grouped and stored...\n",
      "50 out of 78 videos processed, grouped and stored...\n",
      "51 out of 78 videos processed, grouped and stored...\n",
      "52 out of 78 videos processed, grouped and stored...\n",
      "53 out of 78 videos processed, grouped and stored...\n",
      "54 out of 78 videos processed, grouped and stored...\n",
      "55 out of 78 videos processed, grouped and stored...\n",
      "56 out of 78 videos processed, grouped and stored...\n",
      "57 out of 78 videos processed, grouped and stored...\n",
      "58 out of 78 videos processed, grouped and stored...\n",
      "59 out of 78 videos processed, grouped and stored...\n",
      "60 out of 78 videos processed, grouped and stored...\n",
      "61 out of 78 videos processed, grouped and stored...\n",
      "62 out of 78 videos processed, grouped and stored...\n",
      "63 out of 78 videos processed, grouped and stored...\n",
      "64 out of 78 videos processed, grouped and stored...\n",
      "65 out of 78 videos processed, grouped and stored...\n",
      "66 out of 78 videos processed, grouped and stored...\n",
      "67 out of 78 videos processed, grouped and stored...\n",
      "68 out of 78 videos processed, grouped and stored...\n",
      "69 out of 78 videos processed, grouped and stored...\n",
      "70 out of 78 videos processed, grouped and stored...\n",
      "71 out of 78 videos processed, grouped and stored...\n",
      "72 out of 78 videos processed, grouped and stored...\n",
      "73 out of 78 videos processed, grouped and stored...\n",
      "74 out of 78 videos processed, grouped and stored...\n",
      "75 out of 78 videos processed, grouped and stored...\n",
      "76 out of 78 videos processed, grouped and stored...\n",
      "77 out of 78 videos processed, grouped and stored...\n",
      "78 out of 78 videos processed, grouped and stored...\n"
     ]
    }
   ],
   "source": [
    "createNestedDictionariesPerGestures(knot_list, needle_list, suture_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
